{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í†µí•© ìƒëª…ê³¼í•™ ì—°êµ¬ ì—ì´ì „íŠ¸ - Amazon Bedrock AgentCore\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ëª¨ë“  ë…¸íŠ¸ë¶(01~04)ì˜ ë„êµ¬ë“¤ì„ í†µí•©í•œ ì¢…í•©ì ì¸ ìƒëª…ê³¼í•™ ì—°êµ¬ ì—ì´ì „íŠ¸ë¥¼ Amazon Bedrock AgentCore Runtimeìœ¼ë¡œ ë°°í¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "## í†µí•©ë˜ëŠ” ê¸°ëŠ¥\n",
    "- **ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤** (01_external_dbs): Arxiv, ChEMBL, PubMed, ClinicalTrials\n",
    "- **ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤** (02_internal_dbs): PostgreSQL ì„ìƒ/ìœ ì „ì²´ ë°ì´í„°\n",
    "- **í•˜ì´ë¸Œë¦¬ë“œ ë„êµ¬** (03_hybrid_tools): Knowledge Base, Redshift ë“±\n",
    "- **ë‹¨ë°±ì§ˆ ì„¤ê³„** (04_protein_design): AWS HealthOmics ì›Œí¬í”Œë¡œìš°\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- ëª¨ë“  ë„êµ¬ë¥¼ í†µí•©í•œ ì¢…í•© Agent êµ¬í˜„\n",
    "- AgentCore Runtimeì— ë°°í¬ ë° ìš´ì˜\n",
    "- ë‹¤ì–‘í•œ ìƒëª…ê³¼í•™ ì—°êµ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "%pip install bedrock-agentcore-starter-toolkit strands-agents strands-agents-tools boto3 \\\n",
    "    mcp arxiv chembl-webresource-client python-dateutil pubmedmcp \\\n",
    "    psycopg2-binary --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:05.334794Z",
     "iopub.status.busy": "2025-09-29T09:20:05.334352Z",
     "iopub.status.idle": "2025-09-29T09:20:06.415212Z",
     "shell.execute_reply": "2025-09-29T09:20:06.414538Z",
     "shell.execute_reply.started": "2025-09-29T09:20:05.334767Z"
    }
   },
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "\n",
    "# AWS SDK\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "\n",
    "# Bedrock AgentCore\n",
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "# Strands Agents\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from strands_tools import calculator\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:06.416956Z",
     "iopub.status.busy": "2025-09-29T09:20:06.416452Z",
     "iopub.status.idle": "2025-09-29T09:20:06.430356Z",
     "shell.execute_reply": "2025-09-29T09:20:06.429727Z",
     "shell.execute_reply.started": "2025-09-29T09:20:06.416924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting integrated_research_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile integrated_research_agent.py\n",
    "\"\"\"\n",
    "í†µí•© ìƒëª…ê³¼í•™ ì—°êµ¬ ì—ì´ì „íŠ¸ for Amazon Bedrock AgentCore\n",
    "ëª¨ë“  ë„êµ¬ í†µí•©: ì™¸ë¶€DB, ë‚´ë¶€DB, í•˜ì´ë¸Œë¦¬ë“œ, ë‹¨ë°±ì§ˆ ì„¤ê³„\n",
    "\"\"\"\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from typing import Dict, Any, List, Optional\n",
    "from collections import defaultdict\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import arxiv\n",
    "from chembl_webresource_client.new_client import new_client as chembl_client\n",
    "import httpx\n",
    "from defusedxml import ElementTree as ET\n",
    "import psycopg2\n",
    "import boto3\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    # dotenvê°€ ì—†ìœ¼ë©´ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì§ì ‘ ì½ê¸°\n",
    "    pass\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# AWS í´ë¼ì´ì–¸íŠ¸\n",
    "omics_client = boto3.client('omics')\n",
    "s3_client = boto3.client('s3')\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "knowledge_base_client = boto3.client('bedrock-agent-runtime')\n",
    "\n",
    "# =========================\n",
    "# 1. ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ë„êµ¬\n",
    "# =========================\n",
    "\n",
    "@tool\n",
    "def search_arxiv(query: str, max_results: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Arxivì—ì„œ í•™ìˆ  ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)\n",
    "    \n",
    "    Returns:\n",
    "        ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = arxiv.Client()\n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        for paper in client.results(search):\n",
    "            results.append({\n",
    "                \"title\": paper.title,\n",
    "                \"authors\": [author.name for author in paper.authors],\n",
    "                \"abstract\": paper.summary[:500],\n",
    "                \"url\": paper.pdf_url,\n",
    "                \"published\": paper.published.isoformat()\n",
    "            })\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Arxiv ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "        return [{\"error\": str(e)}]\n",
    "\n",
    "@tool\n",
    "def search_compound(compound_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"ChEMBLì—ì„œ í™”í•©ë¬¼ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        compound_name: í™”í•©ë¬¼ëª…\n",
    "    \n",
    "    Returns:\n",
    "        í™”í•©ë¬¼ ì •ë³´ ë° í™œì„± ë°ì´í„°\n",
    "    \"\"\"\n",
    "    try:\n",
    "        molecule = chembl_client.molecule.filter(\n",
    "            pref_name__iexact=compound_name\n",
    "        ).only(['molecule_chembl_id', 'pref_name', 'max_phase'])\n",
    "        \n",
    "        if molecule:\n",
    "            mol_data = molecule[0]\n",
    "            # IC50 í™œì„± ë°ì´í„°\n",
    "            activity = chembl_client.activity.filter(\n",
    "                molecule_chembl_id=mol_data['molecule_chembl_id']\n",
    "            ).filter(standard_type=\"IC50\").only(\n",
    "                ['pchembl_value', 'assay_description', 'canonical_smiles']\n",
    "            )[:10]\n",
    "            \n",
    "            return {\n",
    "                \"chembl_id\": mol_data['molecule_chembl_id'],\n",
    "                \"name\": mol_data['pref_name'],\n",
    "                \"max_phase\": mol_data.get('max_phase'),\n",
    "                \"activities\": list(activity)\n",
    "            }\n",
    "        return {\"error\": \"Compound not found\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ChEMBL ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "@tool\n",
    "def search_pubmed(query: str, max_results: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"PubMedì—ì„œ ì˜í•™ ë¬¸í—Œì„ ê²€ìƒ‰í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)\n",
    "    \n",
    "    Returns:\n",
    "        ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    try:\n",
    "        base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n",
    "        \n",
    "        # ê²€ìƒ‰\n",
    "        search_params = {\n",
    "            \"db\": \"pubmed\",\n",
    "            \"term\": query,\n",
    "            \"retmax\": max_results,\n",
    "            \"retmode\": \"json\"\n",
    "        }\n",
    "        \n",
    "        search_response = httpx.get(\n",
    "            f\"{base_url}/esearch.fcgi\",\n",
    "            params=search_params\n",
    "        )\n",
    "        search_data = search_response.json()\n",
    "        \n",
    "        id_list = search_data[\"esearchresult\"].get(\"idlist\", [])\n",
    "        if not id_list:\n",
    "            return []\n",
    "        \n",
    "        # ìƒì„¸ ì •ë³´\n",
    "        fetch_params = {\n",
    "            \"db\": \"pubmed\",\n",
    "            \"id\": \",\".join(id_list),\n",
    "            \"retmode\": \"xml\"\n",
    "        }\n",
    "        \n",
    "        fetch_response = httpx.get(\n",
    "            f\"{base_url}/efetch.fcgi\",\n",
    "            params=fetch_params\n",
    "        )\n",
    "        \n",
    "        # XML íŒŒì‹±\n",
    "        root = ET.fromstring(fetch_response.text)\n",
    "        articles = []\n",
    "        \n",
    "        for article in root.findall(\".//PubmedArticle\"):\n",
    "            title = article.find(\".//ArticleTitle\")\n",
    "            abstract = article.find(\".//AbstractText\")\n",
    "            pmid = article.find(\".//PMID\")\n",
    "            year = article.find(\".//PubDate/Year\")\n",
    "            \n",
    "            articles.append({\n",
    "                \"pmid\": pmid.text if pmid is not None else \"\",\n",
    "                \"title\": title.text if title is not None else \"\",\n",
    "                \"abstract\": abstract.text[:500] if abstract is not None else \"\",\n",
    "                \"year\": year.text if year is not None else \"\"\n",
    "            })\n",
    "        \n",
    "        return articles\n",
    "    except Exception as e:\n",
    "        logger.error(f\"PubMed ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "        return [{\"error\": str(e)}]\n",
    "\n",
    "# =========================\n",
    "# 2. ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ë„êµ¬ (PostgreSQL)\n",
    "# =========================\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • - í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.environ.get('DB_HOST', 'localhost'),\n",
    "    \"port\": int(os.environ.get('DB_PORT', 5432)),\n",
    "    \"database\": os.environ.get('DB_NAME', 'agentdb'),\n",
    "    \"user\": os.environ.get('DB_USER', 'dbadmin'),\n",
    "    \"password\": os.environ.get('DB_PASSWORD', 'postgres')\n",
    "}\n",
    "\n",
    "@tool\n",
    "def query_clinical_database(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"ë‚´ë¶€ PostgreSQL ì„ìƒ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¿¼ë¦¬í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        query: SQL ì¿¼ë¦¬ ë˜ëŠ” ìì—°ì–´ ì§ˆë¬¸\n",
    "    \n",
    "    Returns:\n",
    "        ì¿¼ë¦¬ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        with conn.cursor() as cursor:\n",
    "            # SQL ì¿¼ë¦¬ì¸ì§€ í™•ì¸\n",
    "            if query.strip().upper().startswith(('SELECT', 'WITH')):\n",
    "                cursor.execute(query)\n",
    "            else:\n",
    "                # ìì—°ì–´ë¥¼ ê°„ë‹¨í•œ SQLë¡œ ë³€í™˜ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ NLP í•„ìš”)\n",
    "                cursor.execute(\n",
    "                    \"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\"\n",
    "                )\n",
    "            \n",
    "            results = cursor.fetchall()\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"data\": results[:100],  # ê²°ê³¼ ì œí•œ\n",
    "                \"count\": len(results)\n",
    "            }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Database ì¿¼ë¦¬ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "    finally:\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "\n",
    "@tool\n",
    "def get_database_schema() -> Dict[str, Any]:\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤\n",
    "    \n",
    "    Returns:\n",
    "        í…Œì´ë¸” ë° ì»¬ëŸ¼ ì •ë³´\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT\n",
    "                    c.relname AS table_name,\n",
    "                    a.attname AS column_name,\n",
    "                    pg_catalog.format_type(a.atttypid, a.atttypmod) AS data_type\n",
    "                FROM pg_catalog.pg_attribute a\n",
    "                JOIN pg_catalog.pg_class c ON a.attrelid = c.oid\n",
    "                JOIN pg_catalog.pg_namespace n ON c.relnamespace = n.oid\n",
    "                WHERE a.attnum > 0 AND NOT a.attisdropped\n",
    "                    AND n.nspname = 'public'\n",
    "                    AND c.relkind = 'r'\n",
    "                ORDER BY c.relname, a.attnum;\n",
    "            \"\"\")\n",
    "            \n",
    "            rows = cursor.fetchall()\n",
    "            tables = defaultdict(list)\n",
    "            for table_name, column_name, data_type in rows:\n",
    "                tables[table_name].append({\n",
    "                    \"column\": column_name,\n",
    "                    \"type\": data_type\n",
    "                })\n",
    "            \n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"schema\": dict(tables)\n",
    "            }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "    finally:\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "\n",
    "# =========================\n",
    "# 3. ë‹¨ë°±ì§ˆ ì„¤ê³„ ë„êµ¬\n",
    "# =========================\n",
    "\n",
    "@tool\n",
    "def trigger_protein_optimization(\n",
    "    sequence: str,\n",
    "    parallel_chains: int = 10,\n",
    "    steps_per_chain: int = 100,\n",
    "    max_mutations: int = 15\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"ë‹¨ë°±ì§ˆ ì„œì—´ ìµœì í™” ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        sequence: ë‹¨ë°±ì§ˆ ì„œì—´ (ì•„ë¯¸ë…¸ì‚°)\n",
    "        parallel_chains: ë³‘ë ¬ ì²´ì¸ ìˆ˜\n",
    "        steps_per_chain: ì²´ì¸ë‹¹ ë‹¨ê³„ ìˆ˜\n",
    "        max_mutations: ìµœëŒ€ ë³€ì´ ìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì •ë³´\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ì„œì—´ ê²€ì¦\n",
    "        valid_amino_acids = set('ACDEFGHIKLMNPQRSTVWY')\n",
    "        if not all(aa in valid_amino_acids for aa in sequence.upper()):\n",
    "            return {\"error\": \"Invalid amino acid sequence\"}\n",
    "        \n",
    "        # ì›Œí¬í”Œë¡œìš° íŒŒë¼ë¯¸í„°\n",
    "        workflow_id = os.environ.get('WORKFLOW_ID', '8600464')\n",
    "        role_arn = os.environ.get('WORKFLOW_ROLE_ARN')\n",
    "        s3_bucket = os.environ.get('S3_BUCKET')\n",
    "        \n",
    "        # HealthOmics ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "        response = omics_client.start_run(\n",
    "            workflowId=workflow_id,\n",
    "            roleArn=role_arn,\n",
    "            outputUri=f\"s3://{s3_bucket}/outputs\",\n",
    "            parameters={\n",
    "                \"sequence\": sequence,\n",
    "                \"parallel_chains\": str(parallel_chains),\n",
    "                \"steps_per_chain\": str(steps_per_chain),\n",
    "                \"max_mutations\": str(max_mutations)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"started\",\n",
    "            \"run_id\": response['id'],\n",
    "            \"arn\": response['arn']\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ë‹¨ë°±ì§ˆ ìµœì í™” ì‹œì‘ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "@tool\n",
    "def monitor_protein_workflow(run_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"ë‹¨ë°±ì§ˆ ìµœì í™” ì›Œí¬í”Œë¡œìš° ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        run_id: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ID\n",
    "    \n",
    "    Returns:\n",
    "        ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë° ê²°ê³¼\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = omics_client.get_run(id=run_id)\n",
    "        \n",
    "        status = response['status']\n",
    "        result = {\n",
    "            \"status\": status,\n",
    "            \"run_id\": run_id\n",
    "        }\n",
    "        \n",
    "        if status == \"COMPLETED\":\n",
    "            # ê²°ê³¼ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°\n",
    "            output_uri = response.get('outputUri')\n",
    "            if output_uri:\n",
    "                result[\"output_location\"] = output_uri\n",
    "                # S3ì—ì„œ ê²°ê³¼ ì½ê¸° (ê°„ë‹¨í•œ ì˜ˆì‹œ)\n",
    "                bucket = output_uri.split('/')[2]\n",
    "                key = '/'.join(output_uri.split('/')[3:])\n",
    "                try:\n",
    "                    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "                    result[\"optimized_sequence\"] = obj['Body'].read().decode('utf-8')\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ì›Œí¬í”Œë¡œìš° ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# =========================\n",
    "# 4. Knowledge Base ë„êµ¬\n",
    "# =========================\n",
    "\n",
    "@tool\n",
    "def query_knowledge_base(query: str, kb_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Amazon Bedrock Knowledge Baseë¥¼ ì¿¼ë¦¬í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        kb_id: Knowledge Base ID (ì„ íƒ)\n",
    "    \n",
    "    Returns:\n",
    "        ê²€ìƒ‰ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    try:\n",
    "        kb_id = kb_id or os.environ.get('KNOWLEDGE_BASE_ID')\n",
    "        if not kb_id:\n",
    "            return {\"error\": \"Knowledge Base ID not configured\"}\n",
    "        \n",
    "        response = knowledge_base_client.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalQuery={'text': query},\n",
    "            retrievalConfiguration={\n",
    "                'vectorSearchConfiguration': {\n",
    "                    'numberOfResults': 5\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        for item in response.get('retrievalResults', []):\n",
    "            results.append({\n",
    "                \"content\": item['content']['text'],\n",
    "                \"score\": item.get('score', 0)\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"results\": results\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Knowledge Base ì¿¼ë¦¬ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# =========================\n",
    "# ë©”ì¸ Agent ì„¤ì •\n",
    "# =========================\n",
    "\n",
    "# ëª¨ë¸ ì„¤ì •\n",
    "model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "model = BedrockModel(model_id=model_id)\n",
    "\n",
    "# í†µí•© Agent ìƒì„±\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    tools=[\n",
    "        # ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤\n",
    "        search_arxiv,\n",
    "        search_compound,\n",
    "        search_pubmed,\n",
    "        # ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤\n",
    "        query_clinical_database,\n",
    "        get_database_schema,\n",
    "        # ë‹¨ë°±ì§ˆ ì„¤ê³„\n",
    "        trigger_protein_optimization,\n",
    "        monitor_protein_workflow,\n",
    "        # Knowledge Base\n",
    "        query_knowledge_base\n",
    "    ],\n",
    "    system_prompt=\"\"\"ë‹¹ì‹ ì€ ì¢…í•©ì ì¸ ìƒëª…ê³¼í•™ ì—°êµ¬ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "    \n",
    "    ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:\n",
    "    1. **ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤**: Arxiv, ChEMBL, PubMedë¥¼ í†µí•œ ë¬¸í—Œ ë° í™”í•©ë¬¼ ê²€ìƒ‰\n",
    "    2. **ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL ì„ìƒ/ìœ ì „ì²´ ë°ì´í„° ë¶„ì„\n",
    "    3. **ë‹¨ë°±ì§ˆ ì„¤ê³„**: AWS HealthOmicsë¥¼ í†µí•œ ë‹¨ë°±ì§ˆ ìµœì í™”\n",
    "    4. **Knowledge Base**: ì¡°ì§ ë‚´ë¶€ ì§€ì‹ ê²€ìƒ‰\n",
    "    \n",
    "    ì—°êµ¬ìì˜ ì§ˆë¬¸ì— ëŒ€í•´:\n",
    "    - ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©\n",
    "    - ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ í¬ê´„ì ì¸ ë‹µë³€ ì œê³µ\n",
    "    - ê³¼í•™ì  ì •í™•ì„± ìœ ì§€\n",
    "    - í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì‘ë‹µ\"\"\"\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def integrated_research_agent(payload: Dict[str, Any]) -> str:\n",
    "    \"\"\"AgentCore ì—”íŠ¸ë¦¬í¬ì¸íŠ¸\"\"\"\n",
    "    user_input = payload.get(\"prompt\", \"\")\n",
    "    logger.info(f\"Processing request: {user_input}\")\n",
    "    \n",
    "    try:\n",
    "        response = agent(user_input)\n",
    "        return response.message['content'][0]['text']\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {str(e)}\")\n",
    "        return f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. í†µí•© Agent êµ¬í˜„\n",
    "\n",
    "ëª¨ë“  ë…¸íŠ¸ë¶ì˜ ë„êµ¬ë“¤ì„ í•˜ë‚˜ì˜ Agentì— í†µí•©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:06.431400Z",
     "iopub.status.busy": "2025-09-29T09:20:06.431173Z",
     "iopub.status.idle": "2025-09-29T09:20:06.444836Z",
     "shell.execute_reply": "2025-09-29T09:20:06.444090Z",
     "shell.execute_reply.started": "2025-09-29T09:20:06.431381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting integrated_research_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile integrated_research_agent.py\n",
    "\"\"\"\n",
    "í†µí•© ìƒëª…ê³¼í•™ ì—°êµ¬ ì—ì´ì „íŠ¸ for Amazon Bedrock AgentCore\n",
    "ëª¨ë“  ë„êµ¬ í†µí•©: ì™¸ë¶€DB, ë‚´ë¶€DB, í•˜ì´ë¸Œë¦¬ë“œ, ë‹¨ë°±ì§ˆ ì„¤ê³„\n",
    "\"\"\"\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from typing import Dict, Any, List, Optional\n",
    "from collections import defaultdict\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import arxiv\n",
    "from chembl_webresource_client.new_client import new_client as chembl_client\n",
    "import httpx\n",
    "from defusedxml import ElementTree as ET\n",
    "import psycopg2\n",
    "import boto3\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# AWS í´ë¼ì´ì–¸íŠ¸\n",
    "omics_client = boto3.client('omics')\n",
    "s3_client = boto3.client('s3')\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "knowledge_base_client = boto3.client('bedrock-agent-runtime')\n",
    "\n",
    "# =========================\n",
    "# 1. ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ë„êµ¬\n",
    "# =========================\n",
    "\n",
    "@tool\n",
    "def search_arxiv(query: str, max_results: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Arxivì—ì„œ í•™ìˆ  ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)\n",
    "    \n",
    "    Returns:\n",
    "        ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = arxiv.Client()\n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        for paper in client.results(search):\n",
    "            results.append({\n",
    "                \"title\": paper.title,\n",
    "                \"authors\": [author.name for author in paper.authors],\n",
    "                \"abstract\": paper.summary[:500],\n",
    "                \"url\": paper.pdf_url,\n",
    "                \"published\": paper.published.isoformat()\n",
    "            })\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Arxiv ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "        return [{\"error\": str(e)}]\n",
    "\n",
    "@tool\n",
    "def search_compound(compound_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"ChEMBLì—ì„œ í™”í•©ë¬¼ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        compound_name: í™”í•©ë¬¼ëª…\n",
    "    \n",
    "    Returns:\n",
    "        í™”í•©ë¬¼ ì •ë³´ ë° í™œì„± ë°ì´í„°\n",
    "    \"\"\"\n",
    "    try:\n",
    "        molecule = chembl_client.molecule.filter(\n",
    "            pref_name__iexact=compound_name\n",
    "        ).only(['molecule_chembl_id', 'pref_name', 'max_phase'])\n",
    "        \n",
    "        if molecule:\n",
    "            mol_data = molecule[0]\n",
    "            # IC50 í™œì„± ë°ì´í„°\n",
    "            activity = chembl_client.activity.filter(\n",
    "                molecule_chembl_id=mol_data['molecule_chembl_id']\n",
    "            ).filter(standard_type=\"IC50\").only(\n",
    "                ['pchembl_value', 'assay_description', 'canonical_smiles']\n",
    "            )[:10]\n",
    "            \n",
    "            return {\n",
    "                \"chembl_id\": mol_data['molecule_chembl_id'],\n",
    "                \"name\": mol_data['pref_name'],\n",
    "                \"max_phase\": mol_data.get('max_phase'),\n",
    "                \"activities\": list(activity)\n",
    "            }\n",
    "        return {\"error\": \"Compound not found\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ChEMBL ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "@tool\n",
    "def search_pubmed(query: str, max_results: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"PubMedì—ì„œ ì˜í•™ ë¬¸í—Œì„ ê²€ìƒ‰í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)\n",
    "    \n",
    "    Returns:\n",
    "        ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    try:\n",
    "        base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n",
    "        \n",
    "        # ê²€ìƒ‰\n",
    "        search_params = {\n",
    "            \"db\": \"pubmed\",\n",
    "            \"term\": query,\n",
    "            \"retmax\": max_results,\n",
    "            \"retmode\": \"json\"\n",
    "        }\n",
    "        \n",
    "        search_response = httpx.get(\n",
    "            f\"{base_url}/esearch.fcgi\",\n",
    "            params=search_params\n",
    "        )\n",
    "        search_data = search_response.json()\n",
    "        \n",
    "        id_list = search_data[\"esearchresult\"].get(\"idlist\", [])\n",
    "        if not id_list:\n",
    "            return []\n",
    "        \n",
    "        # ìƒì„¸ ì •ë³´\n",
    "        fetch_params = {\n",
    "            \"db\": \"pubmed\",\n",
    "            \"id\": \",\".join(id_list),\n",
    "            \"retmode\": \"xml\"\n",
    "        }\n",
    "        \n",
    "        fetch_response = httpx.get(\n",
    "            f\"{base_url}/efetch.fcgi\",\n",
    "            params=fetch_params\n",
    "        )\n",
    "        \n",
    "        # XML íŒŒì‹±\n",
    "        root = ET.fromstring(fetch_response.text)\n",
    "        articles = []\n",
    "        \n",
    "        for article in root.findall(\".//PubmedArticle\"):\n",
    "            title = article.find(\".//ArticleTitle\")\n",
    "            abstract = article.find(\".//AbstractText\")\n",
    "            pmid = article.find(\".//PMID\")\n",
    "            year = article.find(\".//PubDate/Year\")\n",
    "            \n",
    "            articles.append({\n",
    "                \"pmid\": pmid.text if pmid is not None else \"\",\n",
    "                \"title\": title.text if title is not None else \"\",\n",
    "                \"abstract\": abstract.text[:500] if abstract is not None else \"\",\n",
    "                \"year\": year.text if year is not None else \"\"\n",
    "            })\n",
    "        \n",
    "        return articles\n",
    "    except Exception as e:\n",
    "        logger.error(f\"PubMed ê²€ìƒ‰ ì˜¤ë¥˜: {e}\")\n",
    "        return [{\"error\": str(e)}]\n",
    "\n",
    "# =========================\n",
    "# 2. ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ë„êµ¬ (PostgreSQL)\n",
    "# =========================\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • - í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.environ.get('DB_HOST', 'localhost'),\n",
    "    \"port\": int(os.environ.get('DB_PORT', 5432)),\n",
    "    \"database\": os.environ.get('DB_NAME', 'agentdb'),\n",
    "    \"user\": os.environ.get('DB_USER', 'dbadmin'),\n",
    "    \"password\": os.environ.get('DB_PASSWORD', 'postgres')\n",
    "}\n",
    "\n",
    "@tool\n",
    "def query_clinical_database(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"ë‚´ë¶€ PostgreSQL ì„ìƒ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¿¼ë¦¬í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        query: SQL ì¿¼ë¦¬ ë˜ëŠ” ìì—°ì–´ ì§ˆë¬¸\n",
    "    \n",
    "    Returns:\n",
    "        ì¿¼ë¦¬ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        with conn.cursor() as cursor:\n",
    "            # SQL ì¿¼ë¦¬ì¸ì§€ í™•ì¸\n",
    "            if query.strip().upper().startswith(('SELECT', 'WITH')):\n",
    "                cursor.execute(query)\n",
    "            else:\n",
    "                # ìì—°ì–´ë¥¼ ê°„ë‹¨í•œ SQLë¡œ ë³€í™˜ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ NLP í•„ìš”)\n",
    "                cursor.execute(\n",
    "                    \"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\"\n",
    "                )\n",
    "            \n",
    "            results = cursor.fetchall()\n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"data\": results[:100],  # ê²°ê³¼ ì œí•œ\n",
    "                \"count\": len(results)\n",
    "            }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Database ì¿¼ë¦¬ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "    finally:\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "\n",
    "@tool\n",
    "def get_database_schema() -> Dict[str, Any]:\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤\n",
    "    \n",
    "    Returns:\n",
    "        í…Œì´ë¸” ë° ì»¬ëŸ¼ ì •ë³´\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT\n",
    "                    c.relname AS table_name,\n",
    "                    a.attname AS column_name,\n",
    "                    pg_catalog.format_type(a.atttypid, a.atttypmod) AS data_type\n",
    "                FROM pg_catalog.pg_attribute a\n",
    "                JOIN pg_catalog.pg_class c ON a.attrelid = c.oid\n",
    "                JOIN pg_catalog.pg_namespace n ON c.relnamespace = n.oid\n",
    "                WHERE a.attnum > 0 AND NOT a.attisdropped\n",
    "                    AND n.nspname = 'public'\n",
    "                    AND c.relkind = 'r'\n",
    "                ORDER BY c.relname, a.attnum;\n",
    "            \"\"\")\n",
    "            \n",
    "            rows = cursor.fetchall()\n",
    "            tables = defaultdict(list)\n",
    "            for table_name, column_name, data_type in rows:\n",
    "                tables[table_name].append({\n",
    "                    \"column\": column_name,\n",
    "                    \"type\": data_type\n",
    "                })\n",
    "            \n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"schema\": dict(tables)\n",
    "            }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "    finally:\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "\n",
    "# =========================\n",
    "# 3. ë‹¨ë°±ì§ˆ ì„¤ê³„ ë„êµ¬\n",
    "# =========================\n",
    "\n",
    "@tool\n",
    "def trigger_protein_optimization(\n",
    "    sequence: str,\n",
    "    parallel_chains: int = 10,\n",
    "    steps_per_chain: int = 100,\n",
    "    max_mutations: int = 15\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"ë‹¨ë°±ì§ˆ ì„œì—´ ìµœì í™” ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        sequence: ë‹¨ë°±ì§ˆ ì„œì—´ (ì•„ë¯¸ë…¸ì‚°)\n",
    "        parallel_chains: ë³‘ë ¬ ì²´ì¸ ìˆ˜\n",
    "        steps_per_chain: ì²´ì¸ë‹¹ ë‹¨ê³„ ìˆ˜\n",
    "        max_mutations: ìµœëŒ€ ë³€ì´ ìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì •ë³´\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ì„œì—´ ê²€ì¦\n",
    "        valid_amino_acids = set('ACDEFGHIKLMNPQRSTVWY')\n",
    "        if not all(aa in valid_amino_acids for aa in sequence.upper()):\n",
    "            return {\"error\": \"Invalid amino acid sequence\"}\n",
    "        \n",
    "        # ì›Œí¬í”Œë¡œìš° íŒŒë¼ë¯¸í„°\n",
    "        workflow_id = os.environ.get('WORKFLOW_ID', '8600464')\n",
    "        role_arn = os.environ.get('WORKFLOW_ROLE_ARN')\n",
    "        s3_bucket = os.environ.get('S3_BUCKET')\n",
    "        \n",
    "        # HealthOmics ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "        response = omics_client.start_run(\n",
    "            workflowId=workflow_id,\n",
    "            roleArn=role_arn,\n",
    "            outputUri=f\"s3://{s3_bucket}/outputs\",\n",
    "            parameters={\n",
    "                \"sequence\": sequence,\n",
    "                \"parallel_chains\": str(parallel_chains),\n",
    "                \"steps_per_chain\": str(steps_per_chain),\n",
    "                \"max_mutations\": str(max_mutations)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"started\",\n",
    "            \"run_id\": response['id'],\n",
    "            \"arn\": response['arn']\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ë‹¨ë°±ì§ˆ ìµœì í™” ì‹œì‘ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "@tool\n",
    "def monitor_protein_workflow(run_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"ë‹¨ë°±ì§ˆ ìµœì í™” ì›Œí¬í”Œë¡œìš° ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        run_id: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ID\n",
    "    \n",
    "    Returns:\n",
    "        ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë° ê²°ê³¼\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = omics_client.get_run(id=run_id)\n",
    "        \n",
    "        status = response['status']\n",
    "        result = {\n",
    "            \"status\": status,\n",
    "            \"run_id\": run_id\n",
    "        }\n",
    "        \n",
    "        if status == \"COMPLETED\":\n",
    "            # ê²°ê³¼ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°\n",
    "            output_uri = response.get('outputUri')\n",
    "            if output_uri:\n",
    "                result[\"output_location\"] = output_uri\n",
    "                # S3ì—ì„œ ê²°ê³¼ ì½ê¸° (ê°„ë‹¨í•œ ì˜ˆì‹œ)\n",
    "                bucket = output_uri.split('/')[2]\n",
    "                key = '/'.join(output_uri.split('/')[3:])\n",
    "                try:\n",
    "                    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "                    result[\"optimized_sequence\"] = obj['Body'].read().decode('utf-8')\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"ì›Œí¬í”Œë¡œìš° ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# =========================\n",
    "# 4. Knowledge Base ë„êµ¬\n",
    "# =========================\n",
    "\n",
    "@tool\n",
    "def query_knowledge_base(query: str, kb_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Amazon Bedrock Knowledge Baseë¥¼ ì¿¼ë¦¬í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "        kb_id: Knowledge Base ID (ì„ íƒ)\n",
    "    \n",
    "    Returns:\n",
    "        ê²€ìƒ‰ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    try:\n",
    "        kb_id = kb_id or os.environ.get('KNOWLEDGE_BASE_ID')\n",
    "        if not kb_id:\n",
    "            return {\"error\": \"Knowledge Base ID not configured\"}\n",
    "        \n",
    "        response = knowledge_base_client.retrieve(\n",
    "            knowledgeBaseId=kb_id,\n",
    "            retrievalQuery={'text': query},\n",
    "            retrievalConfiguration={\n",
    "                'vectorSearchConfiguration': {\n",
    "                    'numberOfResults': 5\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        for item in response.get('retrievalResults', []):\n",
    "            results.append({\n",
    "                \"content\": item['content']['text'],\n",
    "                \"score\": item.get('score', 0)\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"results\": results\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Knowledge Base ì¿¼ë¦¬ ì˜¤ë¥˜: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# =========================\n",
    "# ë©”ì¸ Agent ì„¤ì •\n",
    "# =========================\n",
    "\n",
    "# ëª¨ë¸ ì„¤ì •\n",
    "model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "model = BedrockModel(model_id=model_id)\n",
    "\n",
    "# í†µí•© Agent ìƒì„±\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    tools=[\n",
    "        # ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤\n",
    "        search_arxiv,\n",
    "        search_compound,\n",
    "        search_pubmed,\n",
    "        # ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤\n",
    "        query_clinical_database,\n",
    "        get_database_schema,\n",
    "        # ë‹¨ë°±ì§ˆ ì„¤ê³„\n",
    "        trigger_protein_optimization,\n",
    "        monitor_protein_workflow,\n",
    "        # Knowledge Base\n",
    "        query_knowledge_base\n",
    "    ],\n",
    "    system_prompt=\"\"\"ë‹¹ì‹ ì€ ì¢…í•©ì ì¸ ìƒëª…ê³¼í•™ ì—°êµ¬ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "    \n",
    "    ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:\n",
    "    1. **ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤**: Arxiv, ChEMBL, PubMedë¥¼ í†µí•œ ë¬¸í—Œ ë° í™”í•©ë¬¼ ê²€ìƒ‰\n",
    "    2. **ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL ì„ìƒ/ìœ ì „ì²´ ë°ì´í„° ë¶„ì„\n",
    "    3. **ë‹¨ë°±ì§ˆ ì„¤ê³„**: AWS HealthOmicsë¥¼ í†µí•œ ë‹¨ë°±ì§ˆ ìµœì í™”\n",
    "    4. **Knowledge Base**: ì¡°ì§ ë‚´ë¶€ ì§€ì‹ ê²€ìƒ‰\n",
    "    \n",
    "    ì—°êµ¬ìì˜ ì§ˆë¬¸ì— ëŒ€í•´:\n",
    "    - ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©\n",
    "    - ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ í¬ê´„ì ì¸ ë‹µë³€ ì œê³µ\n",
    "    - ê³¼í•™ì  ì •í™•ì„± ìœ ì§€\n",
    "    - í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì‘ë‹µ\"\"\"\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def integrated_research_agent(payload: Dict[str, Any]) -> str:\n",
    "    \"\"\"AgentCore ì—”íŠ¸ë¦¬í¬ì¸íŠ¸\"\"\"\n",
    "    user_input = payload.get(\"prompt\", \"\")\n",
    "    logger.info(f\"Processing request: {user_input}\")\n",
    "    \n",
    "    try:\n",
    "        response = agent(user_input)\n",
    "        return response.message['content'][0]['text']\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {str(e)}\")\n",
    "        return f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Requirements íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:06.475292Z",
     "iopub.status.busy": "2025-09-29T09:20:06.475007Z",
     "iopub.status.idle": "2025-09-29T09:20:06.480428Z",
     "shell.execute_reply": "2025-09-29T09:20:06.479653Z",
     "shell.execute_reply.started": "2025-09-29T09:20:06.475259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "strands-agents>=0.5.0\n",
    "strands-agents-tools>=0.1.0\n",
    "boto3>=1.34.0\n",
    "mcp>=0.1.0\n",
    "arxiv>=2.1.0\n",
    "chembl-webresource-client>=0.10.8\n",
    "python-dateutil>=2.8.2\n",
    "httpx>=0.24.0\n",
    "defusedxml>=0.7.1\n",
    "psycopg2-binary>=2.9.0\n",
    "bedrock-agentcore-starter-toolkit\n",
    "pubmedmcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:07.101802Z",
     "iopub.status.busy": "2025-09-29T09:20:07.101537Z",
     "iopub.status.idle": "2025-09-29T09:20:07.266805Z",
     "shell.execute_reply": "2025-09-29T09:20:07.265803Z",
     "shell.execute_reply.started": "2025-09-29T09:20:07.101781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: us-east-1\n",
      "Account ID: 797157869634\n",
      "í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# AWS ì„¸ì…˜ ì„¤ì •\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€ê²½ í•„ìš”)\n",
    "import os\n",
    "\n",
    "# ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •\n",
    "os.environ['DB_HOST'] = 'YOUR_RDS_ENDPOINT'  # RDS ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³€ê²½\n",
    "os.environ['DB_PORT'] = '5432'\n",
    "os.environ['DB_NAME'] = 'agentdb'\n",
    "os.environ['DB_USER'] = 'dbadmin'\n",
    "os.environ['DB_PASSWORD'] = 'postgres'\n",
    "\n",
    "# ë‹¨ë°±ì§ˆ ì„¤ê³„ ì„¤ì •\n",
    "STACK_NAME = 'protein-design-stack'\n",
    "os.environ['WORKFLOW_ID'] = '8600464'  # CloudFormation ì¶œë ¥ì—ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "os.environ['WORKFLOW_ROLE_ARN'] = f'arn:aws:iam::{account_id}:role/{STACK_NAME}-WorkflowExecutionRole'\n",
    "os.environ['S3_BUCKET'] = f'{STACK_NAME}-{account_id}-{region}'\n",
    "\n",
    "# Knowledge Base ì„¤ì •\n",
    "os.environ['KNOWLEDGE_BASE_ID'] = 'YOUR_KB_ID'  # Knowledge Base IDë¡œ ë³€ê²½\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AgentCore Runtime êµ¬ì„± ë° ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:07.694964Z",
     "iopub.status.busy": "2025-09-29T09:20:07.694688Z",
     "iopub.status.idle": "2025-09-29T09:20:07.699068Z",
     "shell.execute_reply": "2025-09-29T09:20:07.698254Z",
     "shell.execute_reply.started": "2025-09-29T09:20:07.694944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "strands-agents>=0.5.0\n",
    "strands-agents-tools>=0.1.0\n",
    "boto3>=1.34.0\n",
    "mcp>=0.1.0\n",
    "arxiv>=2.1.0\n",
    "chembl-webresource-client>=0.10.8\n",
    "python-dateutil>=2.8.2\n",
    "python-dotenv>=1.0.0\n",
    "httpx>=0.24.0\n",
    "defusedxml>=0.7.1\n",
    "psycopg2-binary>=2.9.0\n",
    "bedrock-agentcore-starter-toolkit\n",
    "pubmedmcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:08.049606Z",
     "iopub.status.busy": "2025-09-29T09:20:08.049338Z",
     "iopub.status.idle": "2025-09-29T09:20:08.152424Z",
     "shell.execute_reply": "2025-09-29T09:20:08.151484Z",
     "shell.execute_reply.started": "2025-09-29T09:20:08.049586Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrypoint parsed: file=/home/sagemaker-user/strands-agents-for-life-science/notebook/test/integrated_research_agent.py, bedrock_agentcore_name=integrated_research_agent\n",
      "INFO:bedrock_agentcore_starter_toolkit.utils.runtime.entrypoint:Entrypoint parsed: file=/home/sagemaker-user/strands-agents-for-life-science/notebook/test/integrated_research_agent.py, bedrock_agentcore_name=integrated_research_agent\n",
      "Configuring BedrockAgentCore agent: integrated_lifescience_research_agent\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.configure:Configuring BedrockAgentCore agent: integrated_lifescience_research_agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„± ì™„ë£Œ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">âš ï¸  â„¹ï¸  No container engine found (Docker/Finch/Podman not installed)</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">âœ… Default deployment uses CodeBuild (no container engine needed)</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">ğŸ’¡ Run </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">'agentcore launch'</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\"> for cloud-based building and deployment</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">ğŸ’¡ For local builds, install Docker, Finch, or Podman</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;4;33mâš ï¸  â„¹ï¸  No container engine found \u001b[0m\u001b[1;4;33m(\u001b[0m\u001b[1;4;33mDocker/Finch/Podman not installed\u001b[0m\u001b[1;4;33m)\u001b[0m\n",
       "\u001b[1;4;33mâœ… Default deployment uses CodeBuild \u001b[0m\u001b[1;4;33m(\u001b[0m\u001b[1;4;33mno container engine needed\u001b[0m\u001b[1;4;33m)\u001b[0m\n",
       "\u001b[1;4;33mğŸ’¡ Run \u001b[0m\u001b[4;32m'agentcore launch'\u001b[0m\u001b[1;4;33m for cloud-based building and deployment\u001b[0m\n",
       "\u001b[1;4;33mğŸ’¡ For local builds, install Docker, Finch, or Podman\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">âš ï¸  [WARNING] Platform mismatch: Current system is </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">'linux/amd64'</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\"> but Bedrock AgentCore requires </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">'linux/arm64'</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">.</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">For deployment options and workarounds, see: </span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/getting-started-custom.html</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;4;33mâš ï¸  \u001b[0m\u001b[1;4;33m[\u001b[0m\u001b[1;4;33mWARNING\u001b[0m\u001b[1;4;33m]\u001b[0m\u001b[1;4;33m Platform mismatch: Current system is \u001b[0m\u001b[4;32m'linux/amd64'\u001b[0m\u001b[1;4;33m but Bedrock AgentCore requires \u001b[0m\u001b[4;32m'linux/arm64'\u001b[0m\u001b[1;4;33m.\u001b[0m\n",
       "\u001b[1;4;33mFor deployment options and workarounds, see: \u001b[0m\n",
       "\u001b[4;94mhttps://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/getting-started-custom.html\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated Dockerfile: /home/sagemaker-user/strands-agents-for-life-science/notebook/test/Dockerfile\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.configure:Generated Dockerfile: /home/sagemaker-user/strands-agents-for-life-science/notebook/test/Dockerfile\n",
      "Generated .dockerignore: /home/sagemaker-user/strands-agents-for-life-science/notebook/test/.dockerignore\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.configure:Generated .dockerignore: /home/sagemaker-user/strands-agents-for-life-science/notebook/test/.dockerignore\n",
      "Keeping 'integrated_lifescience_research_agent' as default agent\n",
      "INFO:bedrock_agentcore_starter_toolkit.utils.runtime.config:Keeping 'integrated_lifescience_research_agent' as default agent\n",
      "Bedrock AgentCore configured: /home/sagemaker-user/strands-agents-for-life-science/notebook/test/.bedrock_agentcore.yaml\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:Bedrock AgentCore configured: /home/sagemaker-user/strands-agents-for-life-science/notebook/test/.bedrock_agentcore.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_path=PosixPath('/home/sagemaker-user/strands-agents-for-life-science/notebook/test/.bedrock_agentcore.yaml') dockerfile_path=PosixPath('/home/sagemaker-user/strands-agents-for-life-science/notebook/test/Dockerfile') dockerignore_path=PosixPath('/home/sagemaker-user/strands-agents-for-life-science/notebook/test/.dockerignore') runtime='None' region='us-east-1' account_id='797157869634' execution_role=None ecr_repository=None auto_create_ecr=True\n"
     ]
    }
   ],
   "source": [
    "# AWS ì„¸ì…˜ ì„¤ì •\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "# Runtime ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "agentcore_runtime = Runtime()\n",
    "agent_name = \"integrated_lifescience_research_agent\"\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ë¥¼ .env íŒŒì¼ë¡œ ì €ì¥\n",
    "env_content = f\"\"\"DB_HOST={os.environ['DB_HOST']}\n",
    "DB_PORT={os.environ['DB_PORT']}\n",
    "DB_NAME={os.environ['DB_NAME']}\n",
    "DB_USER={os.environ['DB_USER']}\n",
    "DB_PASSWORD={os.environ['DB_PASSWORD']}\n",
    "WORKFLOW_ID={os.environ['WORKFLOW_ID']}\n",
    "WORKFLOW_ROLE_ARN={os.environ['WORKFLOW_ROLE_ARN']}\n",
    "S3_BUCKET={os.environ['S3_BUCKET']}\n",
    "KNOWLEDGE_BASE_ID={os.environ.get('KNOWLEDGE_BASE_ID', '')}\"\"\"\n",
    "\n",
    "with open('.env', 'w') as f:\n",
    "    f.write(env_content)\n",
    "print(\"âœ… í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"integrated_research_agent.py\",\n",
    "    auto_create_execution_role=True,\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    agent_name=agent_name\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Agent ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:09.104620Z",
     "iopub.status.busy": "2025-09-29T09:20:09.104341Z",
     "iopub.status.idle": "2025-09-29T09:20:53.265358Z",
     "shell.execute_reply": "2025-09-29T09:20:53.264700Z",
     "shell.execute_reply.started": "2025-09-29T09:20:09.104599Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸš€ CodeBuild mode: building in cloud (RECOMMENDED - DEFAULT)\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:ğŸš€ CodeBuild mode: building in cloud (RECOMMENDED - DEFAULT)\n",
      "   â€¢ Build ARM64 containers in the cloud with CodeBuild\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   â€¢ Build ARM64 containers in the cloud with CodeBuild\n",
      "   â€¢ No local Docker required\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   â€¢ No local Docker required\n",
      "ğŸ’¡ Available deployment modes:\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:ğŸ’¡ Available deployment modes:\n",
      "   â€¢ runtime.launch()                           â†’ CodeBuild (current)\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   â€¢ runtime.launch()                           â†’ CodeBuild (current)\n",
      "   â€¢ runtime.launch(local=True)                 â†’ Local development\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   â€¢ runtime.launch(local=True)                 â†’ Local development\n",
      "   â€¢ runtime.launch(local_build=True)           â†’ Local build + cloud deploy (NEW)\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   â€¢ runtime.launch(local_build=True)           â†’ Local build + cloud deploy (NEW)\n",
      "Starting CodeBuild ARM64 deployment for agent 'integrated_lifescience_research_agent' to account 797157869634 (us-east-1)\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Starting CodeBuild ARM64 deployment for agent 'integrated_lifescience_research_agent' to account 797157869634 (us-east-1)\n",
      "Setting up AWS resources (ECR repository, execution roles)...\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Setting up AWS resources (ECR repository, execution roles)...\n",
      "Getting or creating ECR repository for agent: integrated_lifescience_research_agent\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Getting or creating ECR repository for agent: integrated_lifescience_research_agent\n",
      "âœ… ECR repository available: 797157869634.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-integrated_lifescience_research_agent\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:âœ… ECR repository available: 797157869634.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-integrated_lifescience_research_agent\n",
      "Getting or creating execution role for agent: integrated_lifescience_research_agent\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Getting or creating execution role for agent: integrated_lifescience_research_agent\n",
      "Using AWS region: us-east-1, account ID: 797157869634\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Using AWS region: us-east-1, account ID: 797157869634\n",
      "Role name: AmazonBedrockAgentCoreSDKRuntime-us-east-1-547438ac38\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Role name: AmazonBedrockAgentCoreSDKRuntime-us-east-1-547438ac38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ í†µí•© Agentë¥¼ AgentCore Runtimeì— ë°°í¬ ì¤‘...\n",
      "âœ… Reusing existing ECR repository: 797157869634.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-integrated_lifescience_research_agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "âœ… Reusing existing execution role: arn:aws:iam::797157869634:role/AmazonBedrockAgentCoreSDKRuntime-us-east-1-547438ac38\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:âœ… Reusing existing execution role: arn:aws:iam::797157869634:role/AmazonBedrockAgentCoreSDKRuntime-us-east-1-547438ac38\n",
      "âœ… Execution role available: arn:aws:iam::797157869634:role/AmazonBedrockAgentCoreSDKRuntime-us-east-1-547438ac38\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:âœ… Execution role available: arn:aws:iam::797157869634:role/AmazonBedrockAgentCoreSDKRuntime-us-east-1-547438ac38\n",
      "Preparing CodeBuild project and uploading source...\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Preparing CodeBuild project and uploading source...\n",
      "Getting or creating CodeBuild execution role for agent: integrated_lifescience_research_agent\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Getting or creating CodeBuild execution role for agent: integrated_lifescience_research_agent\n",
      "Role name: AmazonBedrockAgentCoreSDKCodeBuild-us-east-1-547438ac38\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Role name: AmazonBedrockAgentCoreSDKCodeBuild-us-east-1-547438ac38\n",
      "Reusing existing CodeBuild execution role: arn:aws:iam::797157869634:role/AmazonBedrockAgentCoreSDKCodeBuild-us-east-1-547438ac38\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Reusing existing CodeBuild execution role: arn:aws:iam::797157869634:role/AmazonBedrockAgentCoreSDKCodeBuild-us-east-1-547438ac38\n",
      "Using .dockerignore with 44 patterns\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Using .dockerignore with 44 patterns\n",
      "Uploaded source to S3: integrated_lifescience_research_agent/source.zip\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Uploaded source to S3: integrated_lifescience_research_agent/source.zip\n",
      "Updated CodeBuild project: bedrock-agentcore-integrated_lifescience_research_agent-builder\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Updated CodeBuild project: bedrock-agentcore-integrated_lifescience_research_agent-builder\n",
      "Starting CodeBuild build (this may take several minutes)...\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Starting CodeBuild build (this may take several minutes)...\n",
      "Starting CodeBuild monitoring...\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Starting CodeBuild monitoring...\n",
      "ğŸ”„ QUEUED started (total: 0s)\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:ğŸ”„ QUEUED started (total: 0s)\n",
      "âœ… QUEUED completed in 1.0s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:âœ… QUEUED completed in 1.0s\n",
      "ğŸ”„ PROVISIONING started (total: 1s)\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:ğŸ”„ PROVISIONING started (total: 1s)\n",
      "âœ… PROVISIONING completed in 8.3s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:âœ… PROVISIONING completed in 8.3s\n",
      "ğŸ”„ DOWNLOAD_SOURCE started (total: 9s)\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:ğŸ”„ DOWNLOAD_SOURCE started (total: 9s)\n",
      "âœ… DOWNLOAD_SOURCE completed in 2.1s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:âœ… DOWNLOAD_SOURCE completed in 2.1s\n",
      "ğŸ”„ BUILD started (total: 11s)\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:ğŸ”„ BUILD started (total: 11s)\n",
      "âœ… BUILD completed in 17.6s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:âœ… BUILD completed in 17.6s\n",
      "ğŸ”„ POST_BUILD started (total: 29s)\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:ğŸ”„ POST_BUILD started (total: 29s)\n",
      "âœ… POST_BUILD completed in 10.3s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:âœ… POST_BUILD completed in 10.3s\n",
      "ğŸ”„ COMPLETED started (total: 39s)\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:ğŸ”„ COMPLETED started (total: 39s)\n",
      "âœ… COMPLETED completed in 1.0s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:âœ… COMPLETED completed in 1.0s\n",
      "ğŸ‰ CodeBuild completed successfully in 0m 40s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:ğŸ‰ CodeBuild completed successfully in 0m 40s\n",
      "CodeBuild completed successfully\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:CodeBuild completed successfully\n",
      "âœ… CodeBuild project configuration saved\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:âœ… CodeBuild project configuration saved\n",
      "Deploying to Bedrock AgentCore...\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Deploying to Bedrock AgentCore...\n",
      "INFO:bedrock_agentcore.runtime.us-east-1:Updating agent ID 'integrated_lifescience_research_agent-m5RclbEjj5' with image URI: 797157869634.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-integrated_lifescience_research_agent:latest\n",
      "INFO:bedrock_agentcore.runtime.us-east-1:Successfully updated agent ID 'integrated_lifescience_research_agent-m5RclbEjj5', ARN: arn:aws:bedrock-agentcore:us-east-1:797157869634:runtime/integrated_lifescience_research_agent-m5RclbEjj5\n",
      "âš ï¸ Session ID will be reset to connect to the updated agent. The previous agent remains accessible via the original session ID: 3404999f-b0ab-48ba-92b3-aac22626b2f7\n",
      "WARNING:bedrock_agentcore_starter_toolkit.operations.runtime.launch:âš ï¸ Session ID will be reset to connect to the updated agent. The previous agent remains accessible via the original session ID: 3404999f-b0ab-48ba-92b3-aac22626b2f7\n",
      "âœ… Agent created/updated: arn:aws:bedrock-agentcore:us-east-1:797157869634:runtime/integrated_lifescience_research_agent-m5RclbEjj5\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:âœ… Agent created/updated: arn:aws:bedrock-agentcore:us-east-1:797157869634:runtime/integrated_lifescience_research_agent-m5RclbEjj5\n",
      "Observability is enabled, configuring Transaction Search...\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Observability is enabled, configuring Transaction Search...\n",
      "CloudWatch Logs resource policy already configured\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.xray:CloudWatch Logs resource policy already configured\n",
      "Transaction Search configuration failed: An error occurred (AccessDeniedException) when calling the UpdateTraceSegmentDestination operation: Access denied to perform: cloudtrail:CreateServiceLinkedChannel (Service: ApplicationSignals, Status Code: 403, Request ID: 479035f1-2323-46be-9e53-478de63a076d) (SDK Attempt Count: 1)\n",
      "WARNING:bedrock_agentcore_starter_toolkit.services.xray:Transaction Search configuration failed: An error occurred (AccessDeniedException) when calling the UpdateTraceSegmentDestination operation: Access denied to perform: cloudtrail:CreateServiceLinkedChannel (Service: ApplicationSignals, Status Code: 403, Request ID: 479035f1-2323-46be-9e53-478de63a076d) (SDK Attempt Count: 1)\n",
      "Agent launch will continue without Transaction Search\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.xray:Agent launch will continue without Transaction Search\n",
      "ğŸ” GenAI Observability Dashboard:\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:ğŸ” GenAI Observability Dashboard:\n",
      "   https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#gen-ai-observability/agent-core\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:   https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#gen-ai-observability/agent-core\n",
      "Polling for endpoint to be ready...\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Polling for endpoint to be ready...\n",
      "Agent endpoint: arn:aws:bedrock-agentcore:us-east-1:797157869634:runtime/integrated_lifescience_research_agent-m5RclbEjj5/runtime-endpoint/DEFAULT\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Agent endpoint: arn:aws:bedrock-agentcore:us-east-1:797157869634:runtime/integrated_lifescience_research_agent-m5RclbEjj5/runtime-endpoint/DEFAULT\n",
      "Deployment completed successfully - Agent: arn:aws:bedrock-agentcore:us-east-1:797157869634:runtime/integrated_lifescience_research_agent-m5RclbEjj5\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Deployment completed successfully - Agent: arn:aws:bedrock-agentcore:us-east-1:797157869634:runtime/integrated_lifescience_research_agent-m5RclbEjj5\n",
      "Built with CodeBuild: bedrock-agentcore-integrated_lifescience_research_agent-builder:04a2ca9f-2c29-499e-adad-c9ab9b5dad14\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:Built with CodeBuild: bedrock-agentcore-integrated_lifescience_research_agent-builder:04a2ca9f-2c29-499e-adad-c9ab9b5dad14\n",
      "Deployed to cloud: arn:aws:bedrock-agentcore:us-east-1:797157869634:runtime/integrated_lifescience_research_agent-m5RclbEjj5\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:Deployed to cloud: arn:aws:bedrock-agentcore:us-east-1:797157869634:runtime/integrated_lifescience_research_agent-m5RclbEjj5\n",
      "ECR image: 797157869634.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-integrated_lifescience_research_agent\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:ECR image: 797157869634.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-integrated_lifescience_research_agent\n",
      "ğŸ” Agent logs available at:\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:ğŸ” Agent logs available at:\n",
      "   /aws/bedrock-agentcore/runtimes/integrated_lifescience_research_agent-m5RclbEjj5-DEFAULT --log-stream-name-prefix \"2025/09/29/\\[runtime-logs]\"\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   /aws/bedrock-agentcore/runtimes/integrated_lifescience_research_agent-m5RclbEjj5-DEFAULT --log-stream-name-prefix \"2025/09/29/\\[runtime-logs]\"\n",
      "   /aws/bedrock-agentcore/runtimes/integrated_lifescience_research_agent-m5RclbEjj5-DEFAULT --log-stream-names \"otel-rt-logs\"\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   /aws/bedrock-agentcore/runtimes/integrated_lifescience_research_agent-m5RclbEjj5-DEFAULT --log-stream-names \"otel-rt-logs\"\n",
      "ğŸ’¡ Tail logs with: aws logs tail /aws/bedrock-agentcore/runtimes/integrated_lifescience_research_agent-m5RclbEjj5-DEFAULT --log-stream-name-prefix \"2025/09/29/\\[runtime-logs]\" --follow\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:ğŸ’¡ Tail logs with: aws logs tail /aws/bedrock-agentcore/runtimes/integrated_lifescience_research_agent-m5RclbEjj5-DEFAULT --log-stream-name-prefix \"2025/09/29/\\[runtime-logs]\" --follow\n",
      "ğŸ’¡ Or view recent logs: aws logs tail /aws/bedrock-agentcore/runtimes/integrated_lifescience_research_agent-m5RclbEjj5-DEFAULT --log-stream-name-prefix \"2025/09/29/\\[runtime-logs]\" --since 1h\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:ğŸ’¡ Or view recent logs: aws logs tail /aws/bedrock-agentcore/runtimes/integrated_lifescience_research_agent-m5RclbEjj5-DEFAULT --log-stream-name-prefix \"2025/09/29/\\[runtime-logs]\" --since 1h\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë°°í¬ ì™„ë£Œ!\n",
      "Agent ARN: arn:aws:bedrock-agentcore:us-east-1:797157869634:runtime/integrated_lifescience_research_agent-m5RclbEjj5\n",
      "ECR URI: 797157869634.dkr.ecr.us-east-1.amazonaws.com/bedrock-agentcore-integrated_lifescience_research_agent\n"
     ]
    }
   ],
   "source": [
    "# AgentCore Runtimeì— ë°°í¬\n",
    "print(\"ğŸš€ í†µí•© Agentë¥¼ AgentCore Runtimeì— ë°°í¬ ì¤‘...\")\n",
    "launch_result = agentcore_runtime.launch()\n",
    "\n",
    "print(f\"\\nâœ… ë°°í¬ ì™„ë£Œ!\")\n",
    "print(f\"Agent ARN: {launch_result.agent_arn}\")\n",
    "print(f\"ECR URI: {launch_result.ecr_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ë°°í¬ ìƒíƒœ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:20:53.266659Z",
     "iopub.status.busy": "2025-09-29T09:20:53.266340Z",
     "iopub.status.idle": "2025-09-29T09:20:53.509219Z",
     "shell.execute_reply": "2025-09-29T09:20:53.508589Z",
     "shell.execute_reply.started": "2025-09-29T09:20:53.266628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Agent ìƒíƒœ í™•ì¸ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieved Bedrock AgentCore status for: integrated_lifescience_research_agent\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:Retrieved Bedrock AgentCore status for: integrated_lifescience_research_agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ìµœì¢… ìƒíƒœ: READY\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# ë°°í¬ ìƒíƒœ í™•ì¸\n",
    "print(\"â³ Agent ìƒíƒœ í™•ì¸ ì¤‘...\")\n",
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(f\"ìƒíƒœ: {status}\")\n",
    "\n",
    "print(f\"\\nâœ… ìµœì¢… ìƒíƒœ: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. í†µí•© Agent í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ë¡œ í†µí•© Agentë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 1: ë¬¸í—Œ ê²€ìƒ‰ í†µí•©\n",
    "query1 = \"\"\"COVID-19 ë°±ì‹ ê³¼ ê´€ë ¨ëœ ìµœì‹  ì—°êµ¬ë¥¼ ì¡°ì‚¬í•´ì£¼ì„¸ìš”. \n",
    "Arxivì™€ PubMedì—ì„œ ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ê³ , ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "print(\"ğŸ“š í…ŒìŠ¤íŠ¸ 1: ë¬¸í—Œ ê²€ìƒ‰ í†µí•©\")\n",
    "print(f\"ì§ˆë¬¸: {query1}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response1 = agentcore_runtime.invoke({\"prompt\": query1})\n",
    "if 'response' in response1:\n",
    "    print(f\"ì‘ë‹µ:\\n{response1['response'][0]}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 2: í™”í•©ë¬¼ ì •ë³´\n",
    "query2 = \"\"\"Aspirinì˜ í™”í•™ì  íŠ¹ì„±ê³¼ ìƒë¬¼í•™ì  í™œì„±ì„ ì¡°ì‚¬í•´ì£¼ì„¸ìš”.\n",
    "ChEMBL ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ IC50 ê°’ê³¼ ê´€ë ¨ ì—°êµ¬ë„ í¬í•¨í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "print(\"ğŸ§ª í…ŒìŠ¤íŠ¸ 2: í™”í•©ë¬¼ ì •ë³´ ê²€ìƒ‰\")\n",
    "print(f\"ì§ˆë¬¸: {query2}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response2 = agentcore_runtime.invoke({\"prompt\": query2})\n",
    "if 'response' in response2:\n",
    "    print(f\"ì‘ë‹µ:\\n{response2['response'][0]}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 ë‚´ë¶€ ë°ì´í„° ë¶„ì„ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:21:32.182362Z",
     "iopub.status.busy": "2025-09-29T09:21:32.182083Z",
     "iopub.status.idle": "2025-09-29T09:21:42.248432Z",
     "shell.execute_reply": "2025-09-29T09:21:42.247739Z",
     "shell.execute_reply.started": "2025-09-29T09:21:32.182340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª í…ŒìŠ¤íŠ¸ 3: ì‚¬ë‚´ ë°ì´í„°ë² ì´ìŠ¤ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\n",
      "ì§ˆë¬¸: ë°ì´í„°ë² ì´ìŠ¤ì— ì–´ë–¤ í…Œì´ë¸”ë“¤ì´ ìˆëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”.\n",
      "============================================================\n",
      "ì‘ë‹µ:\n",
      "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ë¬¸ì œê°€ ìˆì–´ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ëŠ” ìƒíƒœì…ë‹ˆë‹¤. \n",
      "\n",
      "ë‹¤ìŒê³¼ ê°™ì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n",
      "\"ì„œë²„ \"localhost\"(127.0.0.1), í¬íŠ¸ 5432ì— ëŒ€í•œ ì—°ê²° ì‹¤íŒ¨: ì—°ê²°ì´ ê±°ë¶€ë¨. ì„œë²„ê°€ í•´ë‹¹ í˜¸ìŠ¤íŠ¸ì—ì„œ ì‹¤í–‰ ì¤‘ì´ê³  TCP/IP ì—°ê²°ì„ ìˆ˜ë½í•˜ê³  ìˆìŠµë‹ˆê¹Œ?\"\n",
      "\n",
      "ì´ ë¬¸ì œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ë¡œ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
      "1. ë°ì´í„°ë² ì´ìŠ¤ ì„œë²„ê°€ í˜„ì¬ ì‹¤í–‰ë˜ì§€ ì•Šê³  ìˆìŒ\n",
      "2. ë°ì´í„°ë² ì´ìŠ¤ê°€ ë‹¤ë¥¸ í˜¸ìŠ¤íŠ¸ë‚˜ í¬íŠ¸ì—ì„œ ì‹¤í–‰ ì¤‘ì„\n",
      "3. ë°©í™”ë²½ì´ë‚˜ ë„¤íŠ¸ì›Œí¬ ì„¤ì •ìœ¼ë¡œ ì—°ê²°ì´ ì°¨ë‹¨ë¨\n",
      "\n",
      "ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ìì—ê²Œ ì—°ë½í•˜ì—¬ ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ë³´ì‹œê¸¸ ê¶Œì¥ë“œë¦½ë‹ˆë‹¤. í˜¹ì‹œ í•„ìš”í•˜ì‹  ë‹¤ë¥¸ ì •ë³´ë‚˜ ë„ì›€ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 2: í™”í•©ë¬¼ ì •ë³´\n",
    "query3 = \"\"\"ë°ì´í„°ë² ì´ìŠ¤ì— ì–´ë–¤ í…Œì´ë¸”ë“¤ì´ ìˆëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "print(\"ğŸ§ª í…ŒìŠ¤íŠ¸ 3: ì‚¬ë‚´ ë°ì´í„°ë² ì´ìŠ¤ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\")\n",
    "print(f\"ì§ˆë¬¸: {query3}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response3 = agentcore_runtime.invoke({\"prompt\": query3})\n",
    "if 'response' in response3:\n",
    "    print(f\"ì‘ë‹µ:\\n{response3['response'][0]}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 ë‹¨ë°±ì§ˆ ì„¤ê³„ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 4: ë‹¨ë°±ì§ˆ ìµœì í™”\n",
    "test_sequence = \"EVQLVETGGGLVQPGGSLRLSCAASGFTLNSYGISWVRQAPGKGPEWVS\"\n",
    "query4 = f\"\"\"ë‹¤ìŒ í•­ì²´ ì„œì—´ì„ ìµœì í™”í•´ì£¼ì„¸ìš”: {test_sequence}\n",
    "ì•ˆì •ì„±ê³¼ ê²°í•© ì¹œí™”ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ ìµœì í™”í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "print(\"ğŸ§¬ í…ŒìŠ¤íŠ¸ 4: ë‹¨ë°±ì§ˆ ì„¤ê³„\")\n",
    "print(f\"ì§ˆë¬¸: {query4}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response4 = agentcore_runtime.invoke({\"prompt\": query4})\n",
    "if 'response' in response4:\n",
    "    print(f\"ì‘ë‹µ:\\n{response4['response'][0]}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 ë³µí•© ì—°êµ¬ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ 5: ë³µí•© ì—°êµ¬ ì§ˆë¬¸\n",
    "query5 = \"\"\"ì•Œì¸ í•˜ì´ë¨¸ë³‘ ì¹˜ë£Œë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì ‘ê·¼ë²•ì— ëŒ€í•´ ì¢…í•©ì ìœ¼ë¡œ ì¡°ì‚¬í•´ì£¼ì„¸ìš”:\n",
    "1. ìµœì‹  ì—°êµ¬ ë…¼ë¬¸ (Arxiv, PubMed)\n",
    "2. í˜„ì¬ ì„ìƒì‹œí—˜ ì¤‘ì¸ ì•½ë¬¼ (ChEMBL)\n",
    "3. ìš°ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ì˜ ê´€ë ¨ í™˜ì ë°ì´í„°\n",
    "4. íƒ€ìš° ë‹¨ë°±ì§ˆ ì‘ì§‘ ì–µì œë¥¼ ìœ„í•œ í©íƒ€ì´ë“œ ì„¤ê³„ ê°€ëŠ¥ì„±\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ”¬ í…ŒìŠ¤íŠ¸ 5: ë³µí•© ì—°êµ¬ ì§ˆë¬¸\")\n",
    "print(f\"ì§ˆë¬¸: {query5}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response5 = agentcore_runtime.invoke({\"prompt\": query5})\n",
    "if 'response' in response5:\n",
    "    print(f\"ì‘ë‹µ:\\n{response5['response'][0]}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CloudWatch ë©”íŠ¸ë¦­ í™•ì¸\n",
    "cloudwatch = boto3.client('cloudwatch', region_name=region)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "end_time = datetime.utcnow()\n",
    "start_time = end_time - timedelta(hours=1)\n",
    "\n",
    "try:\n",
    "    metrics = cloudwatch.get_metric_statistics(\n",
    "        Namespace='AWS/BedrockAgentCore',\n",
    "        MetricName='InvocationCount',\n",
    "        Dimensions=[\n",
    "            {'Name': 'AgentName', 'Value': agent_name}\n",
    "        ],\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=300,\n",
    "        Statistics=['Sum']\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸ“Š ìµœê·¼ 1ì‹œê°„ í˜¸ì¶œ í†µê³„:\")\n",
    "    for datapoint in metrics.get('Datapoints', []):\n",
    "        print(f\"  ì‹œê°„: {datapoint['Timestamp']}, í˜¸ì¶œ ìˆ˜: {datapoint['Sum']}\")\n",
    "        \n",
    "    # í‰ê·  ì‘ë‹µ ì‹œê°„\n",
    "    latency_metrics = cloudwatch.get_metric_statistics(\n",
    "        Namespace='AWS/BedrockAgentCore',\n",
    "        MetricName='InvocationLatency',\n",
    "        Dimensions=[\n",
    "            {'Name': 'AgentName', 'Value': agent_name}\n",
    "        ],\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=300,\n",
    "        Statistics=['Average']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâ±ï¸ í‰ê·  ì‘ë‹µ ì‹œê°„:\")\n",
    "    for datapoint in latency_metrics.get('Datapoints', []):\n",
    "        print(f\"  ì‹œê°„: {datapoint['Timestamp']}, í‰ê· : {datapoint['Average']:.2f}ms\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ì •ë¦¬ (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Runtime ì‚­ì œ (í•„ìš”ì‹œì—ë§Œ ì‹¤í–‰)\n",
    "# ì£¼ì˜: ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´ ë°°í¬ëœ Agentê°€ ì‚­ì œë©ë‹ˆë‹¤!\n",
    "\n",
    "# cleanup = input(\"ì •ë§ë¡œ Agentë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): \")\n",
    "# if cleanup.lower() == 'yes':\n",
    "#     agentcore_control_client = boto3.client(\n",
    "#         'bedrock-agentcore-control',\n",
    "#         region_name=region\n",
    "#     )\n",
    "#     \n",
    "#     ecr_client = boto3.client('ecr', region_name=region)\n",
    "#     \n",
    "#     try:\n",
    "#         # Runtime ì‚­ì œ\n",
    "#         runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "#             agentRuntimeId=launch_result.agent_id\n",
    "#         )\n",
    "#         \n",
    "#         # ECR ë¦¬í¬ì§€í† ë¦¬ ì‚­ì œ\n",
    "#         ecr_response = ecr_client.delete_repository(\n",
    "#             repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "#             force=True\n",
    "#         )\n",
    "#         \n",
    "#         print(\"âœ… Agent ì •ë¦¬ ì™„ë£Œ\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìš”ì•½\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ëª¨ë“  ìƒëª…ê³¼í•™ ì—°êµ¬ ë„êµ¬ë¥¼ í†µí•©í•œ ì¢…í•© Agentë¥¼ Amazon Bedrock AgentCore Runtimeì— ì„±ê³µì ìœ¼ë¡œ ë°°í¬í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### í†µí•©ëœ ê¸°ëŠ¥:\n",
    "- âœ… **ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤**: Arxiv, ChEMBL, PubMed ë¬¸í—Œ ë° í™”í•©ë¬¼ ê²€ìƒ‰\n",
    "- âœ… **ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL ì„ìƒ/ìœ ì „ì²´ ë°ì´í„° ë¶„ì„\n",
    "- âœ… **ë‹¨ë°±ì§ˆ ì„¤ê³„**: AWS HealthOmics ì›Œí¬í”Œë¡œìš° ê¸°ë°˜ ìµœì í™”\n",
    "- âœ… **Knowledge Base**: ì¡°ì§ ë‚´ë¶€ ì§€ì‹ ê²€ìƒ‰ ë° í™œìš©\n",
    "\n",
    "### ì£¼ìš” ì„±ê³¼:\n",
    "- ëª¨ë“  ë„êµ¬ë¥¼ í•˜ë‚˜ì˜ Agentë¡œ í†µí•©\n",
    "- ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ì—ì„œ í™•ì¥ ê°€ëŠ¥í•œ ë°°í¬\n",
    "- ì‹¤ì‹œê°„ ì—°êµ¬ ì§ˆë¬¸ ì²˜ë¦¬\n",
    "- ë‹¤ì–‘í•œ ìƒëª…ê³¼í•™ ì—°êµ¬ ì‹œë‚˜ë¦¬ì˜¤ ì§€ì›\n",
    "\n",
    "### í™œìš© ì‹œë‚˜ë¦¬ì˜¤:\n",
    "1. **ì‹ ì•½ ê°œë°œ**: íƒ€ê²Ÿ ë°œêµ´ë¶€í„° ë¦¬ë“œ ìµœì í™”ê¹Œì§€\n",
    "2. **ì •ë°€ ì˜ë£Œ**: í™˜ì ë§ì¶¤í˜• ì¹˜ë£Œ ì „ëµ ìˆ˜ë¦½\n",
    "3. **ë°”ì´ì˜¤ë§ˆì»¤ ë°œêµ´**: ì§„ë‹¨ ë° ì˜ˆí›„ ë§ˆì»¤ ê°œë°œ\n",
    "4. **ë‹¨ë°±ì§ˆ ê³µí•™**: ì¹˜ë£Œìš© í•­ì²´ ë° íš¨ì†Œ ì„¤ê³„\n",
    "5. **ì„ìƒ ì—°êµ¬**: ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì§€ì›\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„:\n",
    "1. ì¶”ê°€ ë°ì´í„° ì†ŒìŠ¤ í†µí•© (KEGG, UniProt ë“±)\n",
    "2. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ êµ¬í˜„\n",
    "3. ë©€í‹°ëª¨ë‹¬ ì§€ì› (ì´ë¯¸ì§€, êµ¬ì¡° ë°ì´í„°)\n",
    "4. ì‚¬ìš©ì ì¸ì¦ ë° ì ‘ê·¼ ì œì–´\n",
    "5. ì—°êµ¬ ê²°ê³¼ ìë™ ë³´ê³ ì„œ ìƒì„±"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
